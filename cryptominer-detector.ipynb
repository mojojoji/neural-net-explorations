{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 100)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dataset/cryptominer_commands.txt', 'r', encoding='utf-8') as f:\n",
    "    crypto_lines = f.readlines()\n",
    "\n",
    "with open('dataset/non_cryptominer_commands.txt', 'r', encoding='utf-8') as f:\n",
    "    noncrypto_lines = f.readlines()\n",
    "\n",
    "len(crypto_lines), len(noncrypto_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisation and training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([156, 200]), torch.Size([156]))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "command_max_length = 200\n",
    "\n",
    "def convert_lines_to_token_tensors(lines,): \n",
    "    data = [enc.encode(line) for line in lines]\n",
    "    padded_lists = [lst + [0] * (command_max_length - len(lst)) for lst in data]\n",
    "\n",
    "    tensor_data = torch.tensor(padded_lists).long()\n",
    "    return tensor_data\n",
    "\n",
    "X = convert_lines_to_token_tensors(crypto_lines + noncrypto_lines)\n",
    "Y = torch.cat([torch.ones(len(crypto_lines)), torch.zeros(len(noncrypto_lines))])\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = enc.n_vocab # Total number of tokens in the vocabulary for the tiktoken encoding\n",
    "embedding_dim = 16 # Dimension of the embedding vector per token. Each token will be converted to this size vector and later will be transformed to have inner meaning\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class CryptoMinerDetectionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.flatten_layer = torch.nn.Flatten()\n",
    "        self.linear_layer = torch.nn.Linear(embedding_dim * command_max_length, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs, targets = None):\n",
    "        # Forward pass\n",
    "        token_embeddings = self.embedding_layer(inputs)\n",
    "        flatten_layer_output = self.flatten_layer(token_embeddings)\n",
    "        linear_layer_output = self.linear_layer(flatten_layer_output)\n",
    "        logits = self.sigmoid(linear_layer_output)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(-1), targets)\n",
    "        return logits, loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CryptoMinerDetectionModel()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "inputs = X\n",
    "targets =  Y\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(253.7101, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for steps in range(1000):\n",
    "    logits, loss = model(inputs, targets)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.9998]]), None)\n"
     ]
    }
   ],
   "source": [
    "test_input = \"/usr/bin/node /pitcher/pitcher-agent.cjs containers exec run --id 4074f312-5bae-4d5a-97e1-1b8ca53d9b41 --workspace /project/sandbox --interactive --tty --verbose --command pnpm dev\"\n",
    "test_input_tensor = convert_lines_to_token_tensors([test_input])\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test_input_tensor)\n",
    "    print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
